---
title: "Laporan Praktikum 6 AMP"
author: "Antonius Aditya Rizky Wijaya"
date: "2025-02-27"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Linear Models and Regularization Methods

> Kode halaman 268:

```{r}
library(ISLR2)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
```

```{r}
Hitters <- na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
```

> Kode halaman 275

```{r}
x <- model.matrix(Salary ~ ., Hitters)[, -1]
y <- Hitters$Salary
```

> Kode halaman 276

```{r}
set.seed(1)
train <- sample(1:nrow(x), nrow(x) / 2)
test <- (-train)
y.test <- y[test]
```

## PCR and PLS Regression
### Principal Components Regression
```{r}
library(pls)
set.seed(2)
pcr.fit <- pcr(Salary ~ ., data = Hitters, scale = TRUE,
    validation = "CV")
```

```{r}
summary(pcr.fit)
```

```{r}
validationplot(pcr.fit, val.type = "MSEP")
```

```{r}
set.seed(1)
pcr.fit <- pcr(Salary ~ ., data = Hitters, subset = train,
    scale = TRUE, validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
```

```{r}
pcr.pred <- predict(pcr.fit, x[test, ], ncomp = 5)
mean((pcr.pred - y.test)^2)
```

```{r}
pcr.fit <- pcr(y ~ x, scale = TRUE, ncomp = 5)
summary(pcr.fit)
```

# Unsupervised Learning

## Principal Components Analysis

```{r}
states <- row.names(USArrests)
states
```

```{r}
names(USArrests)
```

```{r}
apply(USArrests, 2, mean)
```

```{r}
apply(USArrests, 2, var)
```

```{r}
pr.out <- prcomp(USArrests, scale = TRUE)
```

```{r}
names(pr.out)
```

```{r}
pr.out$center
pr.out$scale
```

```{r}
pr.out$rotation
```

```{r}
dim(pr.out$x)
```

```{r}
biplot(pr.out, scale = 0)
```

```{r}
pr.out$rotation = -pr.out$rotation
pr.out$x = -pr.out$x
biplot(pr.out, scale = 0)
```

```{r}
pr.out$sdev
```

```{r}
pr.var <- pr.out$sdev^2
pr.var
```

```{r}
pve <- pr.var / sum(pr.var)
pve
```

```{r}
par(mfrow = c(1, 2))
plot(pve, xlab = "Principal Component",
    ylab = "Proportion of Variance Explained", ylim = c(0, 1),
    type = "b")
plot(cumsum(pve), xlab = "Principal Component",
    ylab = "Cumulative Proportion of Variance Explained",
    ylim = c(0, 1), type = "b")
```

```{r}
a <- c(1, 2, 8, -3)
cumsum(a)
```

## NCI60 Data Example

```{r}
library(ISLR2)
nci.labs <- NCI60$labs
nci.data <- NCI60$data
```

```{r}
dim(nci.data)
```

```{r}
nci.labs[1:4]
table(nci.labs)
```

### PCA on the NCI60 Data

```{r}
pr.out <- prcomp(nci.data, scale = TRUE)
```

```{r}
Cols <- function(vec) {
   cols <- rainbow(length(unique(vec)))
   return(cols[as.numeric(as.factor(vec))])
 }
```

```{r}
par(mfrow = c(1, 2))
plot(pr.out$x[, 1:2], col = Cols(nci.labs), pch = 19,
    xlab = "Z1", ylab = "Z2")
plot(pr.out$x[, c(1, 3)], col = Cols(nci.labs), pch = 19,
    xlab = "Z1", ylab = "Z3")
```

```{r}
summary(pr.out)
```

```{r}
plot(pr.out)
```

```{r}
pve <- 100 * pr.out$sdev^2 / sum(pr.out$sdev^2)
par(mfrow = c(1, 2))
plot(pve,  type = "o", ylab = "PVE",
    xlab = "Principal Component", col = "blue")
plot(cumsum(pve), type = "o", ylab = "Cumulative PVE",
    xlab = "Principal Component", col = "brown3")
```


# (Subbab 6.6) Exercises Linear Models and Regularization Methods

# Nomor 9

> In this exercise, we will predict the number of applications received using the other variables in the `College` data set.
>
> a. Split the data set into a training set and a test set.

```{r}
data("College")
set.seed(9)
train_index <- sample(1:nrow(College), size = 0.7 * nrow(College))
train_data <- College[train_index, ]
test_data <- College[-train_index, ]
```

> b. Fit a linear model using least squares on the training set, and report the test error obtained.

```{r}
lm_model <- lm(Apps ~ ., data = train_data)
lm_predictions <- predict(lm_model, newdata = test_data)
lm_mse <- mean((test_data$Apps - lm_predictions)^2)
cat("Test Error (MSE) - Linear Regression:", lm_mse, "\n")
```

> e. Fit a PCR model on the training set, with $M$ chosen by cross-validation. Report the test error obtained, along with the value of $M$ selected by cross-validation.

```{r}
library(pls)
set.seed(9)
pcr_model <- pcr(Apps ~ ., data = train_data, scale = TRUE, validation = "CV")
summary(pcr_model)

M_optimal <- which.min(pcr_model$validation$PRESS)
cat("\nJumlah Komponen Optimal (M):", M_optimal, "\n")

pcr_predictions <- predict(pcr_model, newdata = test_data, ncomp = M_optimal)
pcr_mse <- mean((test_data$Apps - pcr_predictions)^2)
cat("Test Error (MSE) - PCR:", pcr_mse, "\n")
```
```{r}
validationplot(pcr_model, val.type = "MSEP")
```
MSEP adalah error prediksi dalam Cross-Validation
Karena MSEP stabil setelah M = 17, maka M optimal = 17 (menghindari overfitting)


# (Subbab 12.6) Exercises Unsupervised Learning

# Nomor 8

> In Section 12.2.3, a formula for calculating PVE was given in Equation 12.10. We also saw that the PVE can be obtained using the `sdev` output of the `prcomp()` function.
>
> On the `USArrests` data, calculate PVE in two ways:

> a. Using the `sdev` output of the `prcomp()` function, as was done in Section 12.2.3.

```{r}
data("USArrests")
hasil_pca <- prcomp(USArrests, center = TRUE, scale. = TRUE)
pve_a <- (hasil_pca$sdev^2) / sum(hasil_pca$sdev^2)
cat("PVE menggunakan sdev dari prcomp():\n")
print(pve_a)
```

> b. By applying Equation 12.10 directly. That is, use the `prcomp()` function to compute the principal component loadings. Then, use those loadings in Equation 12.10 to obtain the PVE. 
>
> These two approaches should give the same results.

```{r}
lambda <- apply(hasil_pca$x, 2, var)
pve_b <- lambda / sum(lambda)
cat("PVE menggunakan Equation 12.10:\n")
print(pve_b)

identical(round(unname(pve_a), 8), round(unname(pve_b), 8))
```
Menggunakan `sdev` dari `prcomp()`lebih sederhana daripada menghitung secara manual dengan Equation 12.10. Kedua metode memberikan hasil yang identik, yang membuktikan keakuratan teori PCA dalam menangkap variansi data. PCA berguna untuk reduksi dimensi, karena kita dapat memilih beberapa PC pertama yang menjelaskan sebagian besar variansi, tanpa kehilangan terlalu banyak informasi.


# Nomor 10

> In this problem, you will generate simulated data, and then perform PCA and $K$-means clustering on the data.
>
> a. Generate a simulated data set with 20 observations in each of three classes (i.e. 60 observations total), and 50 variables. 

```{r}
set.seed(10)
n <- 20
p <- 50
class1 <- matrix(rnorm(n * p, mean = 0), nrow = n, ncol = p)
class2 <- matrix(rnorm(n * p, mean = 3), nrow = n, ncol = p)
class3 <- matrix(rnorm(n * p, mean = -3), nrow = n, ncol = p)
X <- rbind(class1, class2, class3)
true_labels <- rep(1:3, each = n)
```

> b. Perform PCA on the 60 observations and plot the first two principal component score vectors. Use a different color to indicate the observations in each of the three classes. If the three classes appear separated in this plot, then continue on to part (c). If not, then return to part (a) and modify the simulation so that there is greater separation between the three classes. Do not continue to part (c) until the three classes show at least some separation in the first two principal component score vectors.

```{r}
pca_result <- prcomp(X, center = TRUE, scale. = TRUE)
plot(pca_result$x[, 1:2], col = true_labels, pch = 19,
     xlab = "PC1", ylab = "PC2", main = "PCA - PC1 vs PC2")
legend("bottomleft", legend = c("Class 1", "Class 2", "Class 3"),
       col = 1:3, pch = 19)
```
Data simulasi dibuat dengan 3 kelas (masing-masing 20 observasi) dan 50 variabel. PCA digunakan untuk melihat apakah kelas dapat dipisahkan dan ternyata berdasarkan plot kelas dapat dipisahkan.